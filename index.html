<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Jennifer Dy</title> <meta name="author" content="Jennifer Dy"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/northeasternuniversity_logoseal.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://mllabneu.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-S9WLGVQG2G"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-S9WLGVQG2G");</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/students/">Students</a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/cv_jdy.pdf">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span><b>Jennifer</b></span> Dy </h1> <p class="desc">Professor at <a href="https://www.northeastern.edu/" rel="external nofollow noopener" target="_blank">Northeastern University</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> <p>COE Distinguished Professor, ECE Department</p> <br> <p> Director of AI Faculty, Institute for Experiential AI </p> <br> <p> Northeastern University </p> <br> <p> jdy (at) ece (dot) neu (dot) edu </p> </div> <div class="social"> <div class="contact-icons"> <a href="https://scholar.google.com/citations?user=6h7b0fAAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> </div> <div class="contact-note"> </div> </div> </div> <div class="clearfix"> <p>Jennifer G. Dy is a COE Distinguished Professor at the Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, where she first joined the faculty in 2002. She received her M.S. and Ph.D. in 1997 and 2001 respectively from the School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, and her B.S. degree from the Department of Electrical Engineering, University of the Philippines, in 1993.</p> <p>Her research spans both foundations in machine learning and its application to biomedical imaging, health, science and engineering, with research contributions in unsupervised learning, interpretable models, explainable AI, continual learning, dimensionality reduction, feature selection/sparse methods, learning from uncertain experts, active learning, Bayesian models, and deep representation learning. She is Director of AI Faculty at the Institute for Experiential AI, Director of the Machine Learning Lab and is a founding faculty member of the SPIRAL (Signal Processing, Imaging, Reasoning, and Learning) Center at Northeastern.</p> <p>She received an NSF Career award in 2004. She has served or is serving as Secretary for the ICML Board (formerly, International Machine Learning Society), associate editor/editorial board member for the Journal of Machine Learning Research, Machine Learning journal, IEEE Transactions on Pattern Analysis and Machine Intelligence, organizing and or technical program committee member for premier conferences in machine learning, AI, and data mining (ICML, NeurIPS, ACM SIGKDD, AAAI, IJCAI, UAI, AISTATS, ICLR, SIAM SDM), Program Chair for SIAM SDM 2013, ICML 2018, AISTATS 2023, and AAAI 2024.</p> </div> <h2><a href="/news/" style="color: inherit;">NEWS</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Sep 19, 2025</th> <td> I'm excited to announce that two of our papers [DISCO](https://arxiv.org/abs/2509.16820) and [OrdSHAP](https://arxiv.org/abs/2507.11855) were accepted into NeurIPS (2025)! </td> </tr> <tr> <th scope="row">Aug 10, 2025</th> <td> Our work on Large-Scale Scene Reconstruction [LVT](https://toobaimt.github.io/lvt/) was accepted to SIGGRAPH Asia (2025)! </td> </tr> <tr> <th scope="row">Mar 12, 2025</th> <td> I’m happy to announce that our paper on explainability and locality/globalness, <a href="https://arxiv.org/pdf/2411.01126" rel="external nofollow noopener" target="_blank">Axiomatic Explainer Globalness via Optimal Transport</a>, has been accepted into AISTATS (2025). </td> </tr> <tr> <th scope="row">Feb 2, 2025</th> <td> I’m excited to share that our paper <a href="https://openreview.net/forum?id=6N5OM5Duuj" rel="external nofollow noopener" target="_blank">STAR: Stability-Inducing Weight Perturbation for Continual Learning</a> was accepted into ICLR 2025. </td> </tr> <tr> <th scope="row">Jan 30, 2025</th> <td> I’m happy to announce that our paper <a href="https://openreview.net/forum?id=bZzXgheUSD" rel="external nofollow noopener" target="_blank">ADAPT to Robustify Prompt Tuning Vision Transformers</a> was accepted into TMLR. </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">SELECTED PUBLICATIONS</a></h2> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/disco.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="disco.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="torop2025disco" class="col-sm-8"> <div class="title"><a href="https://arxiv.org/abs/2509.16820" rel="external nofollow noopener" target="_blank">DISCO: Disentangled Communication Steering for Large Language Models</a></div> <div class="author"> Max Torop, Aria Masoomi, Masih Eskandar, and <em>Jennifer Dy</em> </div> <div class="periodical"> <em></em> 2025 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/ordshap.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="ordshap.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="hill2025ordshapfeaturepositionimportance" class="col-sm-8"> <div class="title"><a href="https://arxiv.org/abs/2507.11855" rel="external nofollow noopener" target="_blank">OrdShap: Feature Position Importance for Sequential Black-Box Models</a></div> <div class="author"> Davin Hill, Brian L. Hill, Aria Masoomi, Vijay S. Nori, Robert E. Tillman, and <em>Jennifer Dy</em> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/lvt.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="lvt.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="imtiaz2025lvt" class="col-sm-8"> <div class="title"><a href="https://toobaimt.github.io/lvt/" rel="external nofollow noopener" target="_blank">LVT: Large-Scale Scene Reconstruction via Local View Transformers</a></div> <div class="author"> Tooba Imtiaz, Lucy Chai, Kathryn Heal, Xuan Luo, Jungyeon Park, <em>Jennifer Dy</em>, and John Flynn</div> <div class="periodical"> <em></em> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Large transformer models are proving to be a powerful tool for 3D vision and novel view synthesis. However, the standard Transformer’s well-known quadratic complexity makes it difficult to scale these methods to large scenes. To address this challenge, we propose the Local View Transformer (LVT), a large-scale scene reconstruction and novel view synthesis architecture that circumvents the need for the quadratic attention operation. Motivated by the insight that spatially nearby views provide more useful signal about the local scene composition than distant views, our model processes all information in a local neighborhood around each view. To attend to tokens in nearby views, we leverage a novel positional encoding that conditions on the relative geometric transformation between the query and nearby views. We decode the output of our model into a 3D Gaussian Splat scene representation that includes both color and opacity view-dependence. Taken together, the Local View Transformer enables reconstruction of arbitrarily large, high-resolution scenes in a single forward pass.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/axiomatic_explainer.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="axiomatic_explainer.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="hill2024axiomatic" class="col-sm-8"> <div class="title"><a href="https://arxiv.org/pdf/2411.01126" rel="external nofollow noopener" target="_blank">Axiomatic Explainer Globalness via Optimal Transport</a></div> <div class="author"> Davin Hill, Josh Bone, Aria Masoomi, Max Torop, and <em>Jennifer Dy</em> </div> <div class="periodical"> <em>In The 28th International Conference on Artificial Intelligence and Statistics</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Explainability methods are often challenging to evaluate and compare. With a multitude of explainers available, practitioners must often compare and select explainers based on quantitative evaluation metrics. One particular differentiator between explainers is the diversity of explanations for a given dataset; i.e. whether all explanations are identical, unique and uniformly distributed, or somewhere between these two extremes. In this work, we define a complexity measure for explainers, globalness, which enables deeper understanding of the distribution of explanations produced by feature attribution and feature selection methods for a given dataset. We establish the axiomatic properties that any such measure should possess and prove that our proposed measure, Wasserstein Globalness, meets these criteria. We validate the utility of Wasserstein Globalness using image, tabular, and synthetic datasets, empirically showing that it both facilitates meaningful comparison between explainers and improves the selection process for explainability methods.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/star.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="star.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="eskandar2025star" class="col-sm-8"> <div class="title"><a href="https://openreview.net/forum?id=6N5OM5Duuj" rel="external nofollow noopener" target="_blank">STAR: Stability-Inducing Weight Perturbation for Continual Learning</a></div> <div class="author"> Masih Eskandar, Tooba Imtiaz, Davin Hill, Zifeng Wang, and <em>Jennifer Dy</em> </div> <div class="periodical"> <em>In The Thirteenth International Conference on Learning Representations</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/boundaryaware.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="boundaryaware.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="pmlr-v238-hill24a" class="col-sm-8"> <div class="title"><a href="https://proceedings.mlr.press/v238/hill24a.html" rel="external nofollow noopener" target="_blank"> Boundary-Aware Uncertainty for Feature Attribution Explainers </a></div> <div class="author"> Davin Hill, Aria Masoomi, Max Torop, Sandesh Ghimire, and <em>Jennifer Dy</em> </div> <div class="periodical"> <em>In Proceedings of The 27th International Conference on Artificial Intelligence and Statistics</em>, 02–04 may 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://proceedings.mlr.press/v238/hill24a/hill24a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p> Post-hoc explanation methods have become a critical tool for understanding black-box classifiers in high-stakes applications. However, high-performing classifiers are often highly nonlinear and can exhibit complex behavior around the decision boundary, leading to brittle or misleading local explanations. Therefore there is an impending need to quantify the uncertainty of such explanation methods in order to understand when explanations are trustworthy. In this work we propose the Gaussian Process Explanation unCertainty (GPEC) framework, which generates a unified uncertainty estimate combining decision boundary-aware uncertainty with explanation function approximation uncertainty. We introduce a novel geodesic-based kernel, which captures the complexity of the target black-box decision boundary. We show theoretically that the proposed kernel similarity increases with decision boundary complexity. The proposed framework is highly flexible; it can be used with any black-box classifier and feature attribution method. Empirical results on multiple tabular and image datasets show that the GPEC uncertainty estimate improves understanding of explanations as compared to existing methods. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/analyzingrobust.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="analyzingrobust.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="pmlr-v238-q-khan24a" class="col-sm-8"> <div class="title"><a href="https://proceedings.mlr.press/v238/khan24a.html" rel="external nofollow noopener" target="_blank"> Analyzing Explainer Robustness via Probabilistic Lipschitzness of Prediction Functions </a></div> <div class="author"> Zulqarnain Q Khan, Davin Hill, Aria Masoomi, Joshua T Bone, and <em>Jennifer Dy</em> </div> <div class="periodical"> <em>In Proceedings of The 27th International Conference on Artificial Intelligence and Statistics</em>, 02–04 may 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://proceedings.mlr.press/v238/khan24a/khan24a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p> Machine learning methods have significantly improved in their predictive capabilities, but at the same time they are becoming more complex and less transparent. As a result, explainers are often relied on to provide interpretability to these black-box prediction models. As crucial diagnostics tools, it is important that these explainers themselves are robust. In this paper we focus on one particular aspect of robustness, namely that an explainer should give similar explanations for similar data inputs. We formalize this notion by introducing and defining explainer astuteness, analogous to astuteness of prediction functions. Our formalism allows us to connect explainer robustness to the predictor’s probabilistic Lipschitzness, which captures the probability of local smoothness of a function. We provide lower bound guarantees on the astuteness of a variety of explainers (e.g., SHAP, RISE, CXPlain) given the Lipschitzness of the prediction function. These theoretical results imply that locally smooth prediction functions lend themselves to locally robust explanations. We evaluate these results empirically on simulated as well as real datasets. </p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/sh.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="sh.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/nips/ToropMHKID23" class="col-sm-8"> <div class="title"><a href="http://papers.nips.cc/paper_files/paper/2023/hash/9ef5e965720193681fc8d16372ac4717-Abstract-Conference.html" rel="external nofollow noopener" target="_blank">SmoothHess: ReLU Network Feature Interactions via Stein’s Lemma</a></div> <div class="author"> Max Torop, Aria Masoomi, Davin Hill, Kivanç Köse, Stratis Ioannidis, and Jennifer G. Dy</div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, 2023, New Orleans, LA, USA, December 10 - 16, 2023</em>, 02–04 may 2023 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/dhsic.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="dhsic.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/icml/000200SIWD23" class="col-sm-8"> <div class="title"><a href="https://proceedings.mlr.press/v202/wang23ar.html" rel="external nofollow noopener" target="_blank">DualHSIC: HSIC-Bottleneck and Alignment for Continual Learning</a></div> <div class="author"> Zifeng Wang, Zheng Zhan, Yifan Gong, Yucai Shao, Stratis Ioannidis, Yanzhi Wang, and Jennifer G. Dy</div> <div class="periodical"> <em>In International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA</em>, 02–04 may 2023 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/cfw.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="cfw.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/aistats/WuMGD22" class="col-sm-8"> <div class="title"><a href="https://proceedings.mlr.press/v151/tzu-wu22a.html" rel="external nofollow noopener" target="_blank">Deep Layer-wise Networks Have Closed-Form Weights</a></div> <div class="author"> Chieh Tzu Wu, Aria Masoomi, Arthur Gretton, and Jennifer G. Dy</div> <div class="periodical"> <em>In International Conference on Artificial Intelligence and Statistics, AISTATS 2022, 28-30 March 2022, Virtual Event</em>, 02–04 may 2022 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/l2ppreview.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="l2ppreview.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/0002ZL0SRSPDP22" class="col-sm-8"> <div class="title"><a href="https://doi.org/10.1109/CVPR52688.2022.00024" rel="external nofollow noopener" target="_blank">Learning to Prompt for Continual Learning</a></div> <div class="author"> Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer G. Dy, and Tomas Pfister</div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, LA, USA, June 18-24, 2022</em>, 02–04 may 2022 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/bshap.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="bshap.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/iclr/MasoomiHXHSCID22" class="col-sm-8"> <div class="title"><a href="https://openreview.net/forum?id=45Mr7LeKR9" rel="external nofollow noopener" target="_blank">Explanations of Black-Box Models based on Directional Feature Interactions</a></div> <div class="author"> Aria Masoomi, Davin Hill, Zhonghui Xu, Craig P. Hersh, Edwin K. Silverman, Peter J. Castaldi, Stratis Ioannidis, and Jennifer G. Dy</div> <div class="periodical"> <em>In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>, 02–04 may 2022 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/river.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="river.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/corr/abs-2201-02596" class="col-sm-8"> <div class="title"><a href="https://arxiv.org/abs/2201.02596" rel="external nofollow noopener" target="_blank">Explainable deep learning for insights in El Nino and river flows</a></div> <div class="author"> Yumin Liu, Kate Duffy, Jennifer G. Dy, and Auroop R. Ganguly</div> <div class="periodical"> <em>CoRR</em>, 02–04 may 2022 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/mednet.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="mednet.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/mia/KoseBAGLPDBR21" class="col-sm-8"> <div class="title"><a href="https://doi.org/10.1016/j.media.2020.101841" rel="external nofollow noopener" target="_blank">Segmentation of cellular patterns in confocal images of melanocytic lesions in vivo via a multiscale encoder-decoder network (MED-Net)</a></div> <div class="author"> Kivanç Köse, Alican Bozkurt, Christi Alessi-Fox, Melissa Gill, Caterina Longo, Giovanni Pellacani, Jennifer G. Dy, Dana H. Brooks, and Milind Rajadhyaksha</div> <div class="periodical"> <em>Medical Image Anal.</em>, 02–04 may 2021 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/kkl.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="kkl.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/nips/GhimireMD21" class="col-sm-8"> <div class="title"><a href="https://proceedings.neurips.cc/paper/2021/hash/54a367d629152b720749e187b3eaa11b-Abstract.html" rel="external nofollow noopener" target="_blank">Reliable Estimation of KL Divergence using a Discriminator in Reproducing Kernel Hilbert Space</a></div> <div class="author"> Sandesh Ghimire, Aria Masoomi, and Jennifer G. Dy</div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual</em>, 02–04 may 2021 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/ond.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="ond.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/icdm/0002SGCID20" class="col-sm-8"> <div class="title"><a href="https://doi.org/10.1109/ICDM50108.2020.00072" rel="external nofollow noopener" target="_blank">Open-World Class Discovery with Kernel Networks</a></div> <div class="author"> Zifeng Wang, Batool Salehi, Andrey Gritsenko, Kaushik R. Chowdhury, Stratis Ioannidis, and Jennifer G. Dy</div> <div class="periodical"> <em>In 20th IEEE International Conference on Data Mining, ICDM 2020, Sorrento, Italy, November 17-20, 2020</em>, 02–04 may 2020 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <img src="/assets/img/publication_preview/iwfgpreview.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="iwfgpreview.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/nips/MasoomiWZWCD20" class="col-sm-8"> <div class="title"><a href="https://proceedings.neurips.cc/paper/2020/hash/9b10a919ddeb07e103dc05ff523afe38-Abstract.html" rel="external nofollow noopener" target="_blank">Instance-wise Feature Grouping</a></div> <div class="author"> Aria Masoomi, Chieh Wu, Tingting Zhao, Zifeng Wang, Peter J. Castaldi, and Jennifer G. Dy</div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>, 02–04 may 2020 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> </div> <h2><a href="/students/" style="color: inherit;">CURRENT STUDENTS</a></h2> <br><div class="current-students"> <div class="flex-container"> <div class="flex-item"> <img class="student-pic rounded" src="/assets/img/brandon.jpg"><br><h4 class="center-text"><a href="https://bdominique.github.io/" rel="external nofollow noopener" target="_blank">Brandon Dominique</a></h4> </div> <div class="flex-item"> <img class="student-pic rounded" src="/assets/img/masih.jpg"><br><h4 class="center-text"><a href="https://meskandars.github.io/" rel="external nofollow noopener" target="_blank">Masih Eskandar</a></h4> </div> <div class="flex-item"> <img class="student-pic rounded" src="/assets/img/davin.jpg"><br><h4 class="center-text"><a href="https://www.davinhill.me/" rel="external nofollow noopener" target="_blank">Davin Hill</a></h4> </div> <div class="flex-item"> <img class="student-pic rounded" src="/assets/img/ti2.png"><br><h4 class="center-text"><a href="https://toobaimt.github.io/" rel="external nofollow noopener" target="_blank">Tooba Imtiaz</a></h4> </div> <div class="flex-item"> <img class="student-pic rounded" src="/assets/img/prudence.jpg"><br><h4 class="center-text">Prudence Lam</h4> </div> <div class="flex-item"> <img class="student-pic rounded" src="/assets/img/aria.png"><br><h4 class="center-text">Aria Masoomi</h4> </div> <div class="flex-item"> <img class="student-pic rounded" src="/assets/img/ElifnurSunger.png"><br><h4 class="center-text">Elifnur Sunger</h4> </div> <div class="flex-item"> <img class="student-pic rounded" src="/assets/img/fatemeh.jpg"><br><h4 class="center-text">Fatemeh Tohidian</h4> </div> <div class="flex-item"> <img class="student-pic rounded" src="/assets/img/max.png"><br><h4 class="center-text"><a href="https://maxtorop.github.io/" rel="external nofollow noopener" target="_blank">Max Torop</a></h4> </div> </div> </div> <h2>PAST STUDENTS</h2> <br><div class="current-students"> <div class="container"> <div class="flex-container"> <div class="flex-item"> <h5 class="center-text"><a href="https://kingspencer.github.io/" rel="external nofollow noopener" target="_blank">Zifeng Wang</a></h5> <h6 class="center-text">Google</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://zulqarnain.sites.northeastern.edu/" rel="external nofollow noopener" target="_blank">Zulqarnain Khan</a></h5> <h6 class="center-text">Experiential AI</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://www.linkedin.com/in/liuyumin/" rel="external nofollow noopener" target="_blank">Yumin Liu</a></h5> <h6 class="center-text">Amazon</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://www.linkedin.com/in/ilkay-y%C4%B1ld%C4%B1z/" rel="external nofollow noopener" target="_blank">Ilkay Yildiz</a></h5> <h6 class="center-text">BioSensics</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://chiehwu.com/" rel="external nofollow noopener" target="_blank">Chieh Wu</a></h5> <h6 class="center-text">Northeastern Univ.</h6> </div> <div class="flex-item"> <h5 class="center-text">Setareh Ariafar</h5> <h6 class="center-text">Google Brain</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://alicanb.github.io/" rel="external nofollow noopener" target="_blank">Alican Bozkurt</a></h5> <h6 class="center-text">Paige AI</h6> </div> <div class="flex-item"> <h5 class="center-text">Junxiang Chen</h5> <h6 class="center-text">UPitt Postdoc</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://yalechang.github.io/" rel="external nofollow noopener" target="_blank">Yale Chang</a></h5> <h6 class="center-text">Phillips Research</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://www.linkedin.com/in/uri-peer-4a776316/" rel="external nofollow noopener" target="_blank">Uri Peer</a></h5> <h6 class="center-text">MIT Lincoln Labratory</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://sarahmbrown.org/" rel="external nofollow noopener" target="_blank">Sarah Brown</a></h5> <h6 class="center-text">Univ. Rhode Island</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://jsourati.github.io/" rel="external nofollow noopener" target="_blank">Jamshid Sourati</a></h5> <h6 class="center-text">DePaul Univ.</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://www.linkedin.com/in/sindhu-ghanta-b6359021/" rel="external nofollow noopener" target="_blank">Sindhu Ghanta</a></h5> <h6 class="center-text">AIClub</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://projects.iq.harvard.edu/lmi/people/james-ross" rel="external nofollow noopener" target="_blank">James Ross</a></h5> <h6 class="center-text">Harvard Medical School</h6> </div> <div class="flex-item"> <h5 class="center-text">Jing Fan</h5> <h6 class="center-text">Humana</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://www.linkedin.com/in/chrisyany/" rel="external nofollow noopener" target="_blank">Yan Yan</a></h5> <h6 class="center-text">TikTok</h6> </div> <div class="flex-item"> <h5 class="center-text">Donglin Niu</h5> <h6 class="center-text">ByteDance</h6> </div> <div class="flex-item"> <h5 class="center-text">Shyamal Patel</h5> <h6 class="center-text">ŌURA</h6> </div> <div class="flex-item"> <h5 class="center-text">Yue Guan</h5> <h6 class="center-text">Tremor Video</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://www.childrenshospital.org/research/researchers/sila-kurugol" rel="external nofollow noopener" target="_blank">Sila Kurugol</a></h5> <h6 class="center-text">Boston Children’s Hospital</h6> </div> <div class="flex-item"> <h5 class="center-text"><a href="https://www.volkanvural.com/" rel="external nofollow noopener" target="_blank">Volkan Vural</a></h5> <h6 class="center-text">UCSD</h6> </div> <div class="flex-item"> <h5 class="center-text">Ying Cui</h5> <h6 class="center-text">Apple</h6> </div> <div class="flex-item"> <h5 class="center-text">Ting Su</h5> <h6 class="center-text">Mathworks</h6> </div> </div> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Jennifer Dy. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>